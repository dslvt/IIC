{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/slvt/.conda/envs/coco/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "import open_clip\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, _, transform = open_clip.create_model_and_transforms(\n",
    "  model_name=\"coca_ViT-L-14\",\n",
    "  pretrained=\"logs/2023_04_19-19_25_33-model_coca_ViT-L-14-lr_1e-05-b_6-j_2-p_amp/checkpoints/epoch_1.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet('metadata.parquet')\n",
    "data = data[data['part_id'].between(0, 100)]\n",
    "X_train, X_test  = train_test_split(data, test_size=0.2, random_state=42)\n",
    "X_train = X_train[['image_name', 'prompt']].rename(columns={'image_name': 'filepath', 'prompt': 'title'})\n",
    "X_test = X_test[['image_name', 'prompt']].rename(columns={'image_name': 'filepath', 'prompt': 'title'})\n",
    "X_train['filepath'] = 'diff2m/' + X_train['filepath']\n",
    "X_test['filepath'] = 'diff2m/' + X_test['filepath']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('diff2m_data.csv', index=False, sep=\"\\t\")\n",
    "X_test.to_csv('val_data.csv', index=False, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-19,18:14:21 | INFO | Running with a single process. Device cuda:0.\n",
      "2023-04-19,18:14:21 | INFO | Loaded coca_ViT-L-14 model config.\n",
      "2023-04-19,18:14:23 | INFO | Loading pretrained coca_ViT-L-14 weights (mscoco_finetuned_CoCa-ViT-L-14-laion2B-s13B-b90k.bin).\n",
      "2023-04-19,18:14:25 | INFO | Model:\n",
      "2023-04-19,18:14:25 | INFO | CoCa(\n",
      "  (text): TextTransformer(\n",
      "    (token_embedding): Embedding(49408, 768)\n",
      "    (transformer): Transformer(\n",
      "      (resblocks): ModuleList(\n",
      "        (0-11): 12 x ResidualAttentionBlock(\n",
      "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (ls_1): Identity()\n",
      "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (gelu): GELU(approximate='none')\n",
      "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (ls_2): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (visual): VisionTransformer(\n",
      "    (patchnorm_pre_ln): Identity()\n",
      "    (conv1): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14), bias=False)\n",
      "    (patch_dropout): Identity()\n",
      "    (ln_pre): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    (transformer): Transformer(\n",
      "      (resblocks): ModuleList(\n",
      "        (0-23): 24 x ResidualAttentionBlock(\n",
      "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ls_1): Identity()\n",
      "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (gelu): GELU(approximate='none')\n",
      "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ls_2): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (attn_pool): AttentionalPooler(\n",
      "      (attn): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (ln_q): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (ln_k): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (text_decoder): MultimodalTransformer(\n",
      "    (resblocks): ModuleList(\n",
      "      (0-11): 12 x ResidualAttentionBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (ls_1): Identity()\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (gelu): GELU(approximate='none')\n",
      "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (ls_2): Identity()\n",
      "      )\n",
      "    )\n",
      "    (cross_attn): ModuleList(\n",
      "      (0-11): 12 x ResidualAttentionBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (ls_1): Identity()\n",
      "        (ln_1_kv): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (gelu): GELU(approximate='none')\n",
      "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (ls_2): Identity()\n",
      "      )\n",
      "    )\n",
      "    (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n",
      "2023-04-19,18:14:25 | INFO | Params:\n",
      "2023-04-19,18:14:25 | INFO |   accum_freq: 1\n",
      "2023-04-19,18:14:25 | INFO |   aug_cfg: {}\n",
      "2023-04-19,18:14:25 | INFO |   batch_size: 64\n",
      "2023-04-19,18:14:25 | INFO |   beta1: 0.9\n",
      "2023-04-19,18:14:25 | INFO |   beta2: 0.98\n",
      "2023-04-19,18:14:25 | INFO |   checkpoint_path: ./logs/2023_04_19-18_14_21-model_coca_ViT-L-14-lr_0.0005-b_64-j_1-p_amp/checkpoints\n",
      "2023-04-19,18:14:25 | INFO |   coca_caption_loss_weight: 2.0\n",
      "2023-04-19,18:14:25 | INFO |   coca_contrastive_loss_weight: 1.0\n",
      "2023-04-19,18:14:25 | INFO |   copy_codebase: False\n",
      "2023-04-19,18:14:25 | INFO |   csv_caption_key: title\n",
      "2023-04-19,18:14:25 | INFO |   csv_img_key: filepath\n",
      "2023-04-19,18:14:25 | INFO |   csv_separator: \t\n",
      "2023-04-19,18:14:25 | INFO |   dataset_resampled: False\n",
      "2023-04-19,18:14:25 | INFO |   dataset_type: auto\n",
      "2023-04-19,18:14:25 | INFO |   ddp_static_graph: False\n",
      "2023-04-19,18:14:25 | INFO |   debug: False\n",
      "2023-04-19,18:14:25 | INFO |   delete_previous_checkpoint: False\n",
      "2023-04-19,18:14:25 | INFO |   device: cuda:0\n",
      "2023-04-19,18:14:25 | INFO |   dist_backend: nccl\n",
      "2023-04-19,18:14:25 | INFO |   dist_url: env://\n",
      "2023-04-19,18:14:25 | INFO |   distill: False\n",
      "2023-04-19,18:14:25 | INFO |   distill_model: None\n",
      "2023-04-19,18:14:25 | INFO |   distill_pretrained: None\n",
      "2023-04-19,18:14:25 | INFO |   distributed: False\n",
      "2023-04-19,18:14:25 | INFO |   epochs: 32\n",
      "2023-04-19,18:14:25 | INFO |   epochs_cooldown: None\n",
      "2023-04-19,18:14:25 | INFO |   eps: 1e-06\n",
      "2023-04-19,18:14:25 | INFO |   force_custom_text: False\n",
      "2023-04-19,18:14:25 | INFO |   force_image_size: None\n",
      "2023-04-19,18:14:25 | INFO |   force_patch_dropout: None\n",
      "2023-04-19,18:14:25 | INFO |   force_quick_gelu: False\n",
      "2023-04-19,18:14:25 | INFO |   gather_with_grad: False\n",
      "2023-04-19,18:14:25 | INFO |   grad_checkpointing: False\n",
      "2023-04-19,18:14:25 | INFO |   grad_clip_norm: None\n",
      "2023-04-19,18:14:25 | INFO |   horovod: False\n",
      "2023-04-19,18:14:25 | INFO |   image_mean: None\n",
      "2023-04-19,18:14:25 | INFO |   image_std: None\n",
      "2023-04-19,18:14:25 | INFO |   imagenet_v2: None\n",
      "2023-04-19,18:14:25 | INFO |   imagenet_val: None\n",
      "2023-04-19,18:14:25 | INFO |   local_loss: False\n",
      "2023-04-19,18:14:25 | INFO |   local_rank: 0\n",
      "2023-04-19,18:14:25 | INFO |   lock_image: False\n",
      "2023-04-19,18:14:25 | INFO |   lock_image_freeze_bn_stats: False\n",
      "2023-04-19,18:14:25 | INFO |   lock_image_unlocked_groups: 0\n",
      "2023-04-19,18:14:25 | INFO |   lock_text: False\n",
      "2023-04-19,18:14:25 | INFO |   lock_text_freeze_layer_norm: False\n",
      "2023-04-19,18:14:25 | INFO |   lock_text_unlocked_layers: 0\n",
      "2023-04-19,18:14:25 | INFO |   log_every_n_steps: 100\n",
      "2023-04-19,18:14:25 | INFO |   log_level: 20\n",
      "2023-04-19,18:14:25 | INFO |   log_local: False\n",
      "2023-04-19,18:14:25 | INFO |   log_path: ./logs/2023_04_19-18_14_21-model_coca_ViT-L-14-lr_0.0005-b_64-j_1-p_amp/out.log\n",
      "2023-04-19,18:14:25 | INFO |   logs: ./logs/\n",
      "2023-04-19,18:14:25 | INFO |   lr: 0.0005\n",
      "2023-04-19,18:14:25 | INFO |   lr_cooldown_end: 0.0\n",
      "2023-04-19,18:14:25 | INFO |   lr_cooldown_power: 1.0\n",
      "2023-04-19,18:14:25 | INFO |   lr_scheduler: cosine\n",
      "2023-04-19,18:14:25 | INFO |   model: coca_ViT-L-14\n",
      "2023-04-19,18:14:25 | INFO |   name: 2023_04_19-18_14_21-model_coca_ViT-L-14-lr_0.0005-b_64-j_1-p_amp\n",
      "2023-04-19,18:14:25 | INFO |   no_set_device_rank: False\n",
      "2023-04-19,18:14:25 | INFO |   precision: amp\n",
      "2023-04-19,18:14:25 | INFO |   pretrained: mscoco_finetuned_CoCa-ViT-L-14-laion2B-s13B-b90k.bin\n",
      "2023-04-19,18:14:25 | INFO |   pretrained_image: False\n",
      "2023-04-19,18:14:25 | INFO |   rank: 0\n",
      "2023-04-19,18:14:25 | INFO |   remote_sync: None\n",
      "2023-04-19,18:14:25 | INFO |   remote_sync_frequency: 300\n",
      "2023-04-19,18:14:25 | INFO |   remote_sync_protocol: s3\n",
      "2023-04-19,18:14:25 | INFO |   report_to: \n",
      "2023-04-19,18:14:25 | INFO |   resume: None\n",
      "2023-04-19,18:14:25 | INFO |   save_frequency: 1\n",
      "2023-04-19,18:14:25 | INFO |   save_most_recent: False\n",
      "2023-04-19,18:14:25 | INFO |   seed: 0\n",
      "2023-04-19,18:14:25 | INFO |   skip_scheduler: False\n",
      "2023-04-19,18:14:25 | INFO |   tensorboard: False\n",
      "2023-04-19,18:14:25 | INFO |   tensorboard_path: \n",
      "2023-04-19,18:14:25 | INFO |   torchscript: False\n",
      "2023-04-19,18:14:25 | INFO |   trace: False\n",
      "2023-04-19,18:14:25 | INFO |   train_data: None\n",
      "2023-04-19,18:14:25 | INFO |   train_data_upsampling_factors: None\n",
      "2023-04-19,18:14:25 | INFO |   train_num_samples: None\n",
      "2023-04-19,18:14:25 | INFO |   use_bn_sync: False\n",
      "2023-04-19,18:14:25 | INFO |   val_data: val_data.csv\n",
      "2023-04-19,18:14:25 | INFO |   val_frequency: 1\n",
      "2023-04-19,18:14:25 | INFO |   val_num_samples: None\n",
      "2023-04-19,18:14:25 | INFO |   wandb: False\n",
      "2023-04-19,18:14:25 | INFO |   wandb_notes: \n",
      "2023-04-19,18:14:25 | INFO |   wandb_project_name: open-clip\n",
      "2023-04-19,18:14:25 | INFO |   warmup: 10000\n",
      "2023-04-19,18:14:25 | INFO |   wd: 0.2\n",
      "2023-04-19,18:14:25 | INFO |   workers: 1\n",
      "2023-04-19,18:14:25 | INFO |   world_size: 1\n",
      "2023-04-19,18:14:25 | INFO |   zeroshot_frequency: 2\n",
      "2023-04-19,18:14:28 | INFO | Eval Epoch: 0 [64 / 20000]\tClip Loss: 0.277357\t\n",
      "2023-04-19,18:14:28 | INFO | Generative Loss: 12.650537\t\n",
      "2023-04-19,18:15:30 | INFO | Eval Epoch: 0 [6464 / 20000]\tClip Loss: 0.232436\t\n",
      "2023-04-19,18:15:30 | INFO | Generative Loss: 0.247875\t\n",
      "2023-04-19,18:16:35 | INFO | Eval Epoch: 0 [12864 / 20000]\tClip Loss: 0.234687\t\n",
      "2023-04-19,18:16:35 | INFO | Generative Loss: 0.185657\t\n",
      "2023-04-19,18:17:38 | INFO | Eval Epoch: 0 [19264 / 20000]\tClip Loss: 0.240522\t\n",
      "2023-04-19,18:17:38 | INFO | Generative Loss: 0.167276\t\n",
      "2023-04-19,18:17:54 | INFO | Eval Epoch: 0 image_to_text_mean_rank: 78.8552\timage_to_text_median_rank: 2.0000\timage_to_text_R@1: 0.4352\timage_to_text_R@5: 0.6978\timage_to_text_R@10: 0.7760\ttext_to_image_mean_rank: 93.6638\ttext_to_image_median_rank: 2.0000\ttext_to_image_R@1: 0.4704\ttext_to_image_R@5: 0.7311\ttext_to_image_R@10: 0.8057\tclip_val_loss: 0.2416\tepoch: 0.0000\tnum_samples: 20000.0000\tval_generative_loss: 0.1611\n"
     ]
    }
   ],
   "source": [
    "! python -m training.main \\\n",
    "    --val-data=\"val_data.csv\"  \\\n",
    "    --model 'coca_ViT-L-14' \\\n",
    "    --pretrained 'mscoco_finetuned_CoCa-ViT-L-14-laion2B-s13B-b90k.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-19,18:23:39 | INFO | Running with a single process. Device cuda:0.\n",
      "2023-04-19,18:23:39 | INFO | Loaded coca_ViT-L-14 model config.\n",
      "2023-04-19,18:23:42 | INFO | Loading pretrained coca_ViT-L-14 weights (logs/2023_04_12-16_21_27-model_coca_ViT-L-14-lr_1e-05-b_6-j_2-p_amp/checkpoints/epoch_3.pt).\n",
      "2023-04-19,18:23:47 | INFO | Model:\n",
      "2023-04-19,18:23:47 | INFO | CoCa(\n",
      "  (text): TextTransformer(\n",
      "    (token_embedding): Embedding(49408, 768)\n",
      "    (transformer): Transformer(\n",
      "      (resblocks): ModuleList(\n",
      "        (0-11): 12 x ResidualAttentionBlock(\n",
      "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (ls_1): Identity()\n",
      "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (gelu): GELU(approximate='none')\n",
      "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (ls_2): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (visual): VisionTransformer(\n",
      "    (patchnorm_pre_ln): Identity()\n",
      "    (conv1): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14), bias=False)\n",
      "    (patch_dropout): Identity()\n",
      "    (ln_pre): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    (transformer): Transformer(\n",
      "      (resblocks): ModuleList(\n",
      "        (0-23): 24 x ResidualAttentionBlock(\n",
      "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ls_1): Identity()\n",
      "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (gelu): GELU(approximate='none')\n",
      "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ls_2): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (attn_pool): AttentionalPooler(\n",
      "      (attn): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (ln_q): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (ln_k): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (text_decoder): MultimodalTransformer(\n",
      "    (resblocks): ModuleList(\n",
      "      (0-11): 12 x ResidualAttentionBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (ls_1): Identity()\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (gelu): GELU(approximate='none')\n",
      "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (ls_2): Identity()\n",
      "      )\n",
      "    )\n",
      "    (cross_attn): ModuleList(\n",
      "      (0-11): 12 x ResidualAttentionBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (ls_1): Identity()\n",
      "        (ln_1_kv): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (gelu): GELU(approximate='none')\n",
      "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (ls_2): Identity()\n",
      "      )\n",
      "    )\n",
      "    (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n",
      "2023-04-19,18:23:47 | INFO | Params:\n",
      "2023-04-19,18:23:47 | INFO |   accum_freq: 1\n",
      "2023-04-19,18:23:47 | INFO |   aug_cfg: {}\n",
      "2023-04-19,18:23:47 | INFO |   batch_size: 64\n",
      "2023-04-19,18:23:47 | INFO |   beta1: 0.9\n",
      "2023-04-19,18:23:47 | INFO |   beta2: 0.98\n",
      "2023-04-19,18:23:47 | INFO |   checkpoint_path: ./logs/2023_04_19-18_23_39-model_coca_ViT-L-14-lr_0.0005-b_64-j_1-p_amp/checkpoints\n",
      "2023-04-19,18:23:47 | INFO |   coca_caption_loss_weight: 2.0\n",
      "2023-04-19,18:23:47 | INFO |   coca_contrastive_loss_weight: 1.0\n",
      "2023-04-19,18:23:47 | INFO |   copy_codebase: False\n",
      "2023-04-19,18:23:47 | INFO |   csv_caption_key: title\n",
      "2023-04-19,18:23:47 | INFO |   csv_img_key: filepath\n",
      "2023-04-19,18:23:47 | INFO |   csv_separator: \t\n",
      "2023-04-19,18:23:47 | INFO |   dataset_resampled: False\n",
      "2023-04-19,18:23:47 | INFO |   dataset_type: auto\n",
      "2023-04-19,18:23:47 | INFO |   ddp_static_graph: False\n",
      "2023-04-19,18:23:47 | INFO |   debug: False\n",
      "2023-04-19,18:23:47 | INFO |   delete_previous_checkpoint: False\n",
      "2023-04-19,18:23:47 | INFO |   device: cuda:0\n",
      "2023-04-19,18:23:47 | INFO |   dist_backend: nccl\n",
      "2023-04-19,18:23:47 | INFO |   dist_url: env://\n",
      "2023-04-19,18:23:47 | INFO |   distill: False\n",
      "2023-04-19,18:23:47 | INFO |   distill_model: None\n",
      "2023-04-19,18:23:47 | INFO |   distill_pretrained: None\n",
      "2023-04-19,18:23:47 | INFO |   distributed: False\n",
      "2023-04-19,18:23:47 | INFO |   epochs: 32\n",
      "2023-04-19,18:23:47 | INFO |   epochs_cooldown: None\n",
      "2023-04-19,18:23:47 | INFO |   eps: 1e-06\n",
      "2023-04-19,18:23:47 | INFO |   force_custom_text: False\n",
      "2023-04-19,18:23:47 | INFO |   force_image_size: None\n",
      "2023-04-19,18:23:47 | INFO |   force_patch_dropout: None\n",
      "2023-04-19,18:23:47 | INFO |   force_quick_gelu: False\n",
      "2023-04-19,18:23:47 | INFO |   gather_with_grad: False\n",
      "2023-04-19,18:23:47 | INFO |   grad_checkpointing: False\n",
      "2023-04-19,18:23:47 | INFO |   grad_clip_norm: None\n",
      "2023-04-19,18:23:47 | INFO |   horovod: False\n",
      "2023-04-19,18:23:47 | INFO |   image_mean: None\n",
      "2023-04-19,18:23:47 | INFO |   image_std: None\n",
      "2023-04-19,18:23:47 | INFO |   imagenet_v2: None\n",
      "2023-04-19,18:23:47 | INFO |   imagenet_val: None\n",
      "2023-04-19,18:23:47 | INFO |   local_loss: False\n",
      "2023-04-19,18:23:47 | INFO |   local_rank: 0\n",
      "2023-04-19,18:23:47 | INFO |   lock_image: False\n",
      "2023-04-19,18:23:47 | INFO |   lock_image_freeze_bn_stats: False\n",
      "2023-04-19,18:23:47 | INFO |   lock_image_unlocked_groups: 0\n",
      "2023-04-19,18:23:47 | INFO |   lock_text: False\n",
      "2023-04-19,18:23:47 | INFO |   lock_text_freeze_layer_norm: False\n",
      "2023-04-19,18:23:47 | INFO |   lock_text_unlocked_layers: 0\n",
      "2023-04-19,18:23:47 | INFO |   log_every_n_steps: 100\n",
      "2023-04-19,18:23:47 | INFO |   log_level: 20\n",
      "2023-04-19,18:23:47 | INFO |   log_local: False\n",
      "2023-04-19,18:23:47 | INFO |   log_path: ./logs/2023_04_19-18_23_39-model_coca_ViT-L-14-lr_0.0005-b_64-j_1-p_amp/out.log\n",
      "2023-04-19,18:23:47 | INFO |   logs: ./logs/\n",
      "2023-04-19,18:23:47 | INFO |   lr: 0.0005\n",
      "2023-04-19,18:23:47 | INFO |   lr_cooldown_end: 0.0\n",
      "2023-04-19,18:23:47 | INFO |   lr_cooldown_power: 1.0\n",
      "2023-04-19,18:23:47 | INFO |   lr_scheduler: cosine\n",
      "2023-04-19,18:23:47 | INFO |   model: coca_ViT-L-14\n",
      "2023-04-19,18:23:47 | INFO |   name: 2023_04_19-18_23_39-model_coca_ViT-L-14-lr_0.0005-b_64-j_1-p_amp\n",
      "2023-04-19,18:23:47 | INFO |   no_set_device_rank: False\n",
      "2023-04-19,18:23:47 | INFO |   precision: amp\n",
      "2023-04-19,18:23:47 | INFO |   pretrained: logs/2023_04_12-16_21_27-model_coca_ViT-L-14-lr_1e-05-b_6-j_2-p_amp/checkpoints/epoch_3.pt\n",
      "2023-04-19,18:23:47 | INFO |   pretrained_image: False\n",
      "2023-04-19,18:23:47 | INFO |   rank: 0\n",
      "2023-04-19,18:23:47 | INFO |   remote_sync: None\n",
      "2023-04-19,18:23:47 | INFO |   remote_sync_frequency: 300\n",
      "2023-04-19,18:23:47 | INFO |   remote_sync_protocol: s3\n",
      "2023-04-19,18:23:47 | INFO |   report_to: \n",
      "2023-04-19,18:23:47 | INFO |   resume: None\n",
      "2023-04-19,18:23:47 | INFO |   save_frequency: 1\n",
      "2023-04-19,18:23:47 | INFO |   save_most_recent: False\n",
      "2023-04-19,18:23:47 | INFO |   seed: 0\n",
      "2023-04-19,18:23:47 | INFO |   skip_scheduler: False\n",
      "2023-04-19,18:23:47 | INFO |   tensorboard: False\n",
      "2023-04-19,18:23:47 | INFO |   tensorboard_path: \n",
      "2023-04-19,18:23:47 | INFO |   torchscript: False\n",
      "2023-04-19,18:23:47 | INFO |   trace: False\n",
      "2023-04-19,18:23:47 | INFO |   train_data: None\n",
      "2023-04-19,18:23:47 | INFO |   train_data_upsampling_factors: None\n",
      "2023-04-19,18:23:47 | INFO |   train_num_samples: None\n",
      "2023-04-19,18:23:47 | INFO |   use_bn_sync: False\n",
      "2023-04-19,18:23:47 | INFO |   val_data: val_data.csv\n",
      "2023-04-19,18:23:47 | INFO |   val_frequency: 1\n",
      "2023-04-19,18:23:47 | INFO |   val_num_samples: None\n",
      "2023-04-19,18:23:47 | INFO |   wandb: False\n",
      "2023-04-19,18:23:47 | INFO |   wandb_notes: \n",
      "2023-04-19,18:23:47 | INFO |   wandb_project_name: open-clip\n",
      "2023-04-19,18:23:47 | INFO |   warmup: 10000\n",
      "2023-04-19,18:23:47 | INFO |   wd: 0.2\n",
      "2023-04-19,18:23:47 | INFO |   workers: 1\n",
      "2023-04-19,18:23:47 | INFO |   world_size: 1\n",
      "2023-04-19,18:23:47 | INFO |   zeroshot_frequency: 2\n",
      "2023-04-19,18:23:49 | INFO | Eval Epoch: 0 [64 / 20000]\tClip Loss: 0.521857\t\n",
      "2023-04-19,18:23:49 | INFO | Generative Loss: 11.079072\t\n",
      "2023-04-19,18:24:52 | INFO | Eval Epoch: 0 [6464 / 20000]\tClip Loss: 0.285115\t\n",
      "2023-04-19,18:24:52 | INFO | Generative Loss: 0.217355\t\n",
      "2023-04-19,18:25:55 | INFO | Eval Epoch: 0 [12864 / 20000]\tClip Loss: 0.281408\t\n",
      "2023-04-19,18:25:55 | INFO | Generative Loss: 0.162439\t\n",
      "2023-04-19,18:26:57 | INFO | Eval Epoch: 0 [19264 / 20000]\tClip Loss: 0.286332\t\n",
      "2023-04-19,18:26:57 | INFO | Generative Loss: 0.146270\t\n",
      "2023-04-19,18:27:12 | INFO | Eval Epoch: 0 image_to_text_mean_rank: 105.6876\timage_to_text_median_rank: 2.0000\timage_to_text_R@1: 0.4217\timage_to_text_R@5: 0.6718\timage_to_text_R@10: 0.7482\ttext_to_image_mean_rank: 92.2631\ttext_to_image_median_rank: 2.0000\ttext_to_image_R@1: 0.4518\ttext_to_image_R@5: 0.7060\ttext_to_image_R@10: 0.7806\tclip_val_loss: 0.2866\tepoch: 0.0000\tnum_samples: 20000.0000\tval_generative_loss: 0.1409\n"
     ]
    }
   ],
   "source": [
    "! python -m training.main \\\n",
    "    --val-data=\"val_data.csv\"  \\\n",
    "    --model 'coca_ViT-L-14' \\\n",
    "    --pretrained 'logs/2023_04_12-16_21_27-model_coca_ViT-L-14-lr_1e-05-b_6-j_2-p_amp/checkpoints/epoch_3.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-20,09:24:43 | INFO | Running with a single process. Device cuda:0.\n",
      "2023-04-20,09:24:43 | INFO | Loaded coca_ViT-L-14 model config.\n",
      "2023-04-20,09:24:46 | INFO | Loading pretrained coca_ViT-L-14 weights (logs/2023_04_19-19_25_33-model_coca_ViT-L-14-lr_1e-05-b_6-j_2-p_amp/checkpoints/epoch_1.pt).\n",
      "2023-04-20,09:24:50 | INFO | Model:\n",
      "2023-04-20,09:24:50 | INFO | CoCa(\n",
      "  (text): TextTransformer(\n",
      "    (token_embedding): Embedding(49408, 768)\n",
      "    (transformer): Transformer(\n",
      "      (resblocks): ModuleList(\n",
      "        (0-11): 12 x ResidualAttentionBlock(\n",
      "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (ls_1): Identity()\n",
      "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (gelu): GELU(approximate='none')\n",
      "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (ls_2): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (visual): VisionTransformer(\n",
      "    (patchnorm_pre_ln): Identity()\n",
      "    (conv1): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14), bias=False)\n",
      "    (patch_dropout): Identity()\n",
      "    (ln_pre): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    (transformer): Transformer(\n",
      "      (resblocks): ModuleList(\n",
      "        (0-23): 24 x ResidualAttentionBlock(\n",
      "          (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ls_1): Identity()\n",
      "          (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Sequential(\n",
      "            (c_fc): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (gelu): GELU(approximate='none')\n",
      "            (c_proj): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          )\n",
      "          (ls_2): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (attn_pool): AttentionalPooler(\n",
      "      (attn): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "      (ln_q): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (ln_k): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (text_decoder): MultimodalTransformer(\n",
      "    (resblocks): ModuleList(\n",
      "      (0-11): 12 x ResidualAttentionBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (ls_1): Identity()\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (gelu): GELU(approximate='none')\n",
      "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (ls_2): Identity()\n",
      "      )\n",
      "    )\n",
      "    (cross_attn): ModuleList(\n",
      "      (0-11): 12 x ResidualAttentionBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (ls_1): Identity()\n",
      "        (ln_1_kv): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): Sequential(\n",
      "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (gelu): GELU(approximate='none')\n",
      "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (ls_2): Identity()\n",
      "      )\n",
      "    )\n",
      "    (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n",
      "2023-04-20,09:24:50 | INFO | Params:\n",
      "2023-04-20,09:24:50 | INFO |   accum_freq: 1\n",
      "2023-04-20,09:24:50 | INFO |   aug_cfg: {}\n",
      "2023-04-20,09:24:50 | INFO |   batch_size: 64\n",
      "2023-04-20,09:24:50 | INFO |   beta1: 0.9\n",
      "2023-04-20,09:24:50 | INFO |   beta2: 0.98\n",
      "2023-04-20,09:24:50 | INFO |   checkpoint_path: ./logs/2023_04_20-09_24_43-model_coca_ViT-L-14-lr_0.0005-b_64-j_1-p_amp/checkpoints\n",
      "2023-04-20,09:24:50 | INFO |   coca_caption_loss_weight: 2.0\n",
      "2023-04-20,09:24:50 | INFO |   coca_contrastive_loss_weight: 1.0\n",
      "2023-04-20,09:24:50 | INFO |   copy_codebase: False\n",
      "2023-04-20,09:24:50 | INFO |   csv_caption_key: title\n",
      "2023-04-20,09:24:50 | INFO |   csv_img_key: filepath\n",
      "2023-04-20,09:24:50 | INFO |   csv_separator: \t\n",
      "2023-04-20,09:24:50 | INFO |   dataset_resampled: False\n",
      "2023-04-20,09:24:50 | INFO |   dataset_type: auto\n",
      "2023-04-20,09:24:50 | INFO |   ddp_static_graph: False\n",
      "2023-04-20,09:24:50 | INFO |   debug: False\n",
      "2023-04-20,09:24:50 | INFO |   delete_previous_checkpoint: False\n",
      "2023-04-20,09:24:50 | INFO |   device: cuda:0\n",
      "2023-04-20,09:24:50 | INFO |   dist_backend: nccl\n",
      "2023-04-20,09:24:50 | INFO |   dist_url: env://\n",
      "2023-04-20,09:24:50 | INFO |   distill: False\n",
      "2023-04-20,09:24:50 | INFO |   distill_model: None\n",
      "2023-04-20,09:24:50 | INFO |   distill_pretrained: None\n",
      "2023-04-20,09:24:50 | INFO |   distributed: False\n",
      "2023-04-20,09:24:50 | INFO |   epochs: 32\n",
      "2023-04-20,09:24:50 | INFO |   epochs_cooldown: None\n",
      "2023-04-20,09:24:50 | INFO |   eps: 1e-06\n",
      "2023-04-20,09:24:50 | INFO |   force_custom_text: False\n",
      "2023-04-20,09:24:50 | INFO |   force_image_size: None\n",
      "2023-04-20,09:24:50 | INFO |   force_patch_dropout: None\n",
      "2023-04-20,09:24:50 | INFO |   force_quick_gelu: False\n",
      "2023-04-20,09:24:50 | INFO |   gather_with_grad: False\n",
      "2023-04-20,09:24:50 | INFO |   grad_checkpointing: False\n",
      "2023-04-20,09:24:50 | INFO |   grad_clip_norm: None\n",
      "2023-04-20,09:24:50 | INFO |   horovod: False\n",
      "2023-04-20,09:24:50 | INFO |   image_mean: None\n",
      "2023-04-20,09:24:50 | INFO |   image_std: None\n",
      "2023-04-20,09:24:50 | INFO |   imagenet_v2: None\n",
      "2023-04-20,09:24:50 | INFO |   imagenet_val: None\n",
      "2023-04-20,09:24:50 | INFO |   local_loss: False\n",
      "2023-04-20,09:24:50 | INFO |   local_rank: 0\n",
      "2023-04-20,09:24:50 | INFO |   lock_image: False\n",
      "2023-04-20,09:24:50 | INFO |   lock_image_freeze_bn_stats: False\n",
      "2023-04-20,09:24:50 | INFO |   lock_image_unlocked_groups: 0\n",
      "2023-04-20,09:24:50 | INFO |   lock_text: False\n",
      "2023-04-20,09:24:50 | INFO |   lock_text_freeze_layer_norm: False\n",
      "2023-04-20,09:24:50 | INFO |   lock_text_unlocked_layers: 0\n",
      "2023-04-20,09:24:50 | INFO |   log_every_n_steps: 100\n",
      "2023-04-20,09:24:50 | INFO |   log_level: 20\n",
      "2023-04-20,09:24:50 | INFO |   log_local: False\n",
      "2023-04-20,09:24:50 | INFO |   log_path: ./logs/2023_04_20-09_24_43-model_coca_ViT-L-14-lr_0.0005-b_64-j_1-p_amp/out.log\n",
      "2023-04-20,09:24:50 | INFO |   logs: ./logs/\n",
      "2023-04-20,09:24:50 | INFO |   lr: 0.0005\n",
      "2023-04-20,09:24:50 | INFO |   lr_cooldown_end: 0.0\n",
      "2023-04-20,09:24:50 | INFO |   lr_cooldown_power: 1.0\n",
      "2023-04-20,09:24:50 | INFO |   lr_scheduler: cosine\n",
      "2023-04-20,09:24:50 | INFO |   model: coca_ViT-L-14\n",
      "2023-04-20,09:24:50 | INFO |   name: 2023_04_20-09_24_43-model_coca_ViT-L-14-lr_0.0005-b_64-j_1-p_amp\n",
      "2023-04-20,09:24:50 | INFO |   no_set_device_rank: False\n",
      "2023-04-20,09:24:50 | INFO |   precision: amp\n",
      "2023-04-20,09:24:50 | INFO |   pretrained: logs/2023_04_19-19_25_33-model_coca_ViT-L-14-lr_1e-05-b_6-j_2-p_amp/checkpoints/epoch_1.pt\n",
      "2023-04-20,09:24:50 | INFO |   pretrained_image: False\n",
      "2023-04-20,09:24:50 | INFO |   rank: 0\n",
      "2023-04-20,09:24:50 | INFO |   remote_sync: None\n",
      "2023-04-20,09:24:50 | INFO |   remote_sync_frequency: 300\n",
      "2023-04-20,09:24:50 | INFO |   remote_sync_protocol: s3\n",
      "2023-04-20,09:24:50 | INFO |   report_to: \n",
      "2023-04-20,09:24:50 | INFO |   resume: None\n",
      "2023-04-20,09:24:50 | INFO |   save_frequency: 1\n",
      "2023-04-20,09:24:50 | INFO |   save_most_recent: False\n",
      "2023-04-20,09:24:50 | INFO |   seed: 0\n",
      "2023-04-20,09:24:50 | INFO |   skip_scheduler: False\n",
      "2023-04-20,09:24:50 | INFO |   tensorboard: False\n",
      "2023-04-20,09:24:50 | INFO |   tensorboard_path: \n",
      "2023-04-20,09:24:50 | INFO |   torchscript: False\n",
      "2023-04-20,09:24:50 | INFO |   trace: False\n",
      "2023-04-20,09:24:50 | INFO |   train_data: None\n",
      "2023-04-20,09:24:50 | INFO |   train_data_upsampling_factors: None\n",
      "2023-04-20,09:24:50 | INFO |   train_num_samples: None\n",
      "2023-04-20,09:24:50 | INFO |   use_bn_sync: False\n",
      "2023-04-20,09:24:50 | INFO |   val_data: val_data.csv\n",
      "2023-04-20,09:24:50 | INFO |   val_frequency: 1\n",
      "2023-04-20,09:24:50 | INFO |   val_num_samples: None\n",
      "2023-04-20,09:24:50 | INFO |   wandb: False\n",
      "2023-04-20,09:24:50 | INFO |   wandb_notes: \n",
      "2023-04-20,09:24:50 | INFO |   wandb_project_name: open-clip\n",
      "2023-04-20,09:24:50 | INFO |   warmup: 10000\n",
      "2023-04-20,09:24:50 | INFO |   wd: 0.2\n",
      "2023-04-20,09:24:50 | INFO |   workers: 1\n",
      "2023-04-20,09:24:50 | INFO |   world_size: 1\n",
      "2023-04-20,09:24:50 | INFO |   zeroshot_frequency: 2\n",
      "2023-04-20,09:24:52 | INFO | Eval Epoch: 0 [64 / 20000]\tClip Loss: 0.308648\t\n",
      "2023-04-20,09:24:52 | INFO | Generative Loss: 8.450324\t\n",
      "2023-04-20,09:25:54 | INFO | Eval Epoch: 0 [6464 / 20000]\tClip Loss: 0.115884\t\n",
      "2023-04-20,09:25:54 | INFO | Generative Loss: 0.165784\t\n",
      "2023-04-20,09:26:58 | INFO | Eval Epoch: 0 [12864 / 20000]\tClip Loss: 0.121293\t\n",
      "2023-04-20,09:26:58 | INFO | Generative Loss: 0.124411\t\n",
      "2023-04-20,09:28:00 | INFO | Eval Epoch: 0 [19264 / 20000]\tClip Loss: 0.123821\t\n",
      "2023-04-20,09:28:00 | INFO | Generative Loss: 0.112534\t\n",
      "2023-04-20,09:28:15 | INFO | Eval Epoch: 0 image_to_text_mean_rank: 35.8462\timage_to_text_median_rank: 1.0000\timage_to_text_R@1: 0.5070\timage_to_text_R@5: 0.7659\timage_to_text_R@10: 0.8368\ttext_to_image_mean_rank: 37.6324\ttext_to_image_median_rank: 1.0000\ttext_to_image_R@1: 0.5391\ttext_to_image_R@5: 0.8030\ttext_to_image_R@10: 0.8706\tclip_val_loss: 0.1229\tepoch: 0.0000\tnum_samples: 20000.0000\tval_generative_loss: 0.1084\n"
     ]
    }
   ],
   "source": [
    "! python -m training.main \\\n",
    "    --val-data=\"val_data.csv\"  \\\n",
    "    --model 'coca_ViT-L-14' \\\n",
    "    --pretrained 'logs/2023_04_19-19_25_33-model_coca_ViT-L-14-lr_1e-05-b_6-j_2-p_amp/checkpoints/epoch_1.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file, sep='\\t').iloc[:2560]#.iloc[:38400]\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        # image = read_image(img_path)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dataset = ImageDataset('val_data.csv', '', transform=transform)\n",
    "train_dataloader = DataLoader(img_dataset, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [04:58<00:00, 29.90s/it]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# im = Image.open(\"img.jpg\").convert(\"RGB\")\n",
    "# im = transform(im).unsqueeze(0)\n",
    "output_text = []\n",
    "orig_text = []\n",
    "for batch in tqdm(train_dataloader):\n",
    "    train_features, train_labels = batch\n",
    "\n",
    "    with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "        train_features = train_features.to(device)\n",
    "        generated = model.generate(train_features)\n",
    "\n",
    "    for i in range(len(generated)):\n",
    "        output_text.append(open_clip.decode(generated[i]).split(\"<end_of_text>\")[0].replace(\"<start_of_text>\", \"\"))\n",
    "    orig_text.extend(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.08682854120861037, 'precisions': [0.3798662577732345, 0.18555725741057752, 0.13211110048761832, 0.10652273537349152], 'brevity_penalty': 0.48926025088869046, 'length_ratio': 0.5831377370440743, 'translation_length': 46956, 'reference_length': 80523}\n"
     ]
    }
   ],
   "source": [
    "bleu = evaluate.load(\"bleu\")\n",
    "results = bleu.compute(predictions=output_text, references=list(map(lambda x: [x], orig_text)))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "st_model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_embeddings = st_model.encode(orig_text)\n",
    "prompt_embeddings = st_model.encode(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2560, 384)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2560, 384)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5209617\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    return dot(a, b) / (norm(a) * norm(b))\n",
    "\n",
    "scores = []\n",
    "for i in range(prompt_embeddings.shape[1]):\n",
    "    scores.append(cosine_similarity(prompt_embeddings[i], label_embeddings[i]))\n",
    "scores = np.array(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
